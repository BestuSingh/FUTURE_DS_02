{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1480443,"sourceType":"datasetVersion","datasetId":835308},{"sourceId":7683145,"sourceType":"datasetVersion","datasetId":4482846}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-02-23T06:39:08.645568Z","iopub.execute_input":"2024-02-23T06:39:08.645894Z","iopub.status.idle":"2024-02-23T06:39:08.653977Z","shell.execute_reply.started":"2024-02-23T06:39:08.645868Z","shell.execute_reply":"2024-02-23T06:39:08.652883Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image as PILImage\nfrom IPython.display import display\n\n# Load the WebP image using PIL\nimage_filename = '/kaggle/input/salesforecast/Saleforecast.webp'\nwebp_image = PILImage.open(image_filename)\n\n# Convert the image to RGB format (required for PNG)\nrgb_image = webp_image.convert('RGB')\n\n# Display the image\ndisplay(rgb_image)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-23T06:39:10.946114Z","iopub.execute_input":"2024-02-23T06:39:10.946522Z","iopub.status.idle":"2024-02-23T06:39:11.462686Z","shell.execute_reply.started":"2024-02-23T06:39:10.946491Z","shell.execute_reply":"2024-02-23T06:39:11.46129Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1 style=\"font-size: 35px; font-style: Bold; color: black;\">Sales Forecating with TimeSeries, ARIMA, SARIMA, LightGBM, RandomForest, LSTM</h1>\n","metadata":{}},{"cell_type":"markdown","source":"# Importing Necessary Libraries ","metadata":{}},{"cell_type":"code","source":"pip install pmdarima","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:40:00.926575Z","iopub.execute_input":"2024-02-23T06:40:00.926946Z","iopub.status.idle":"2024-02-23T06:40:18.009877Z","shell.execute_reply.started":"2024-02-23T06:40:00.926918Z","shell.execute_reply":"2024-02-23T06:40:18.008132Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime\nfrom pmdarima import auto_arima\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Dense, LSTM\nimport warnings\nwarnings.filterwarnings(\"ignore\") # suppressing warnings","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:40:21.329433Z","iopub.execute_input":"2024-02-23T06:40:21.329888Z","iopub.status.idle":"2024-02-23T06:40:41.009219Z","shell.execute_reply.started":"2024-02-23T06:40:21.32985Z","shell.execute_reply":"2024-02-23T06:40:41.008045Z"},"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/sales-forecasting/train.csv')\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:40:44.676115Z","iopub.execute_input":"2024-02-23T06:40:44.677332Z","iopub.status.idle":"2024-02-23T06:40:44.816147Z","shell.execute_reply.started":"2024-02-23T06:40:44.677295Z","shell.execute_reply":"2024-02-23T06:40:44.815046Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:40:47.909615Z","iopub.execute_input":"2024-02-23T06:40:47.910246Z","iopub.status.idle":"2024-02-23T06:40:47.932739Z","shell.execute_reply.started":"2024-02-23T06:40:47.910214Z","shell.execute_reply":"2024-02-23T06:40:47.931523Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# getting more information from the data\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:40:51.818413Z","iopub.execute_input":"2024-02-23T06:40:51.818833Z","iopub.status.idle":"2024-02-23T06:40:51.863385Z","shell.execute_reply.started":"2024-02-23T06:40:51.818801Z","shell.execute_reply":"2024-02-23T06:40:51.862191Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checking how many rows and columns in the dataset\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:40:54.759758Z","iopub.execute_input":"2024-02-23T06:40:54.760977Z","iopub.status.idle":"2024-02-23T06:40:54.767993Z","shell.execute_reply.started":"2024-02-23T06:40:54.760931Z","shell.execute_reply":"2024-02-23T06:40:54.76698Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# statistical summary\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:40:57.47663Z","iopub.execute_input":"2024-02-23T06:40:57.47707Z","iopub.status.idle":"2024-02-23T06:40:57.504411Z","shell.execute_reply.started":"2024-02-23T06:40:57.47701Z","shell.execute_reply":"2024-02-23T06:40:57.503171Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# printing the column names in the data\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:00.274856Z","iopub.execute_input":"2024-02-23T06:41:00.275303Z","iopub.status.idle":"2024-02-23T06:41:00.286801Z","shell.execute_reply.started":"2024-02-23T06:41:00.27527Z","shell.execute_reply":"2024-02-23T06:41:00.285321Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# data types of columns\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:03.612273Z","iopub.execute_input":"2024-02-23T06:41:03.612711Z","iopub.status.idle":"2024-02-23T06:41:03.623768Z","shell.execute_reply.started":"2024-02-23T06:41:03.612678Z","shell.execute_reply":"2024-02-23T06:41:03.622783Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cleaning Dataset by Removing Missing Values & Duplicates","metadata":{}},{"cell_type":"code","source":"df.isnull().sum().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:07.329833Z","iopub.execute_input":"2024-02-23T06:41:07.330262Z","iopub.status.idle":"2024-02-23T06:41:07.356327Z","shell.execute_reply.started":"2024-02-23T06:41:07.330231Z","shell.execute_reply":"2024-02-23T06:41:07.355243Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.duplicated().any() # use df.drop_duplicates(inplace=True) -> if any duplicates exist in the dataframe","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:10.057601Z","iopub.execute_input":"2024-02-23T06:41:10.057977Z","iopub.status.idle":"2024-02-23T06:41:10.087101Z","shell.execute_reply.started":"2024-02-23T06:41:10.057949Z","shell.execute_reply":"2024-02-23T06:41:10.085928Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# removing missing values\ndf.dropna(axis=0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:15.239778Z","iopub.execute_input":"2024-02-23T06:41:15.240434Z","iopub.status.idle":"2024-02-23T06:41:15.263579Z","shell.execute_reply.started":"2024-02-23T06:41:15.240402Z","shell.execute_reply":"2024-02-23T06:41:15.262289Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Customer Segmentation Analysis","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:19.224592Z","iopub.execute_input":"2024-02-23T06:41:19.224973Z","iopub.status.idle":"2024-02-23T06:41:19.232641Z","shell.execute_reply.started":"2024-02-23T06:41:19.224944Z","shell.execute_reply":"2024-02-23T06:41:19.231324Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = df[['Segment','Country','City','State','Sales']]\ntop_10_sales = features.nlargest(10, 'Sales')\nprint('Top 10 Sales Revenue')\nprint(top_10_sales[['Segment','Country','City','State','Sales']])","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:21.358697Z","iopub.execute_input":"2024-02-23T06:41:21.359148Z","iopub.status.idle":"2024-02-23T06:41:21.376169Z","shell.execute_reply.started":"2024-02-23T06:41:21.359113Z","shell.execute_reply":"2024-02-23T06:41:21.375084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"segment_sales = df.groupby('Segment')['Sales'].sum().sort_values(ascending=False)\nplt.figure(figsize=(20,6))\nplt.subplot(1,3,1)\nplt.subplot(1,3,1)\nsegment_sales.plot(kind='bar',color='green')\nplt.title('Sales by Segment')\nplt.xlabel('Segment')\nplt.ylabel('Total Sales')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:23.991412Z","iopub.execute_input":"2024-02-23T06:41:23.991825Z","iopub.status.idle":"2024-02-23T06:41:24.250643Z","shell.execute_reply.started":"2024-02-23T06:41:23.991792Z","shell.execute_reply":"2024-02-23T06:41:24.249769Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"segment_sales = df.groupby('City')['Sales'].sum().sort_values(ascending=False).head(5)\nplt.figure(figsize=(20,6))\nplt.subplot(1,3,2)\nsegment_sales.plot(kind='bar',color='purple')\nplt.title('Top 5 Cities Based on Sales')\nplt.xlabel('City')\nplt.ylabel('Total Sales')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:27.768296Z","iopub.execute_input":"2024-02-23T06:41:27.76936Z","iopub.status.idle":"2024-02-23T06:41:27.991081Z","shell.execute_reply.started":"2024-02-23T06:41:27.769316Z","shell.execute_reply":"2024-02-23T06:41:27.989868Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"segment_sales = df.groupby('State')['Sales'].sum().sort_values(ascending=False).head(5)\nplt.figure(figsize=(20,6))\nplt.subplot(1,3,3)\nsegment_sales.plot(kind='bar',color='lightgreen')\nplt.title('Top 5 States Based on Sales')\nplt.xlabel('State')\nplt.ylabel('Total Sales')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:31.399307Z","iopub.execute_input":"2024-02-23T06:41:31.399711Z","iopub.status.idle":"2024-02-23T06:41:31.613994Z","shell.execute_reply.started":"2024-02-23T06:41:31.399682Z","shell.execute_reply":"2024-02-23T06:41:31.612677Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"heatmap_data = df.pivot_table(index='Segment', columns='Category', values='Sales', aggfunc='sum')\nplt.figure(figsize=(10,6))\nsns.heatmap(heatmap_data, annot=True, cmap='viridis', fmt='.0f', cbar_kws={'label':'Total Sales'})\nplt.title(\"Segment Sales by Product Category\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:34.77553Z","iopub.execute_input":"2024-02-23T06:41:34.775922Z","iopub.status.idle":"2024-02-23T06:41:35.105966Z","shell.execute_reply.started":"2024-02-23T06:41:34.775895Z","shell.execute_reply":"2024-02-23T06:41:35.105046Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Analyzing Order Fulfilment Efficiency","metadata":{}},{"cell_type":"code","source":"# converting into datetime object\ndf['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\ndf['Ship Date'] = pd.to_datetime(df['Ship Date'], format='%d/%m/%Y')\ndf['Processing Time'] = (df['Ship Date']- df['Order Date']).dt.days\nmedian_processing_time =df.groupby('Sub-Category')['Processing Time'].median().sort_values()\nprint('Median Processing Time for each Product Sub-Category')\nprint(median_processing_time)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:38.654045Z","iopub.execute_input":"2024-02-23T06:41:38.655375Z","iopub.status.idle":"2024-02-23T06:41:38.698117Z","shell.execute_reply.started":"2024-02-23T06:41:38.655318Z","shell.execute_reply":"2024-02-23T06:41:38.696765Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nmedian_processing_time.plot(kind='bar',color='yellow')\nplt.title('Median Processing Time by Product Sub-Category')\nplt.xlabel('Product Sub-Category')\nplt.ylabel('Median Processing Time(Days)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:43.415716Z","iopub.execute_input":"2024-02-23T06:41:43.416157Z","iopub.status.idle":"2024-02-23T06:41:43.783642Z","shell.execute_reply.started":"2024-02-23T06:41:43.416123Z","shell.execute_reply":"2024-02-23T06:41:43.782493Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Analyzing Sales Performance Trend","metadata":{}},{"cell_type":"code","source":"# converting into datetime format\ndf['Order Date']= pd.to_datetime(df['Order Date'])\ndf['Year'] = df['Order Date'].dt.year","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:47.747948Z","iopub.execute_input":"2024-02-23T06:41:47.7488Z","iopub.status.idle":"2024-02-23T06:41:47.774581Z","shell.execute_reply.started":"2024-02-23T06:41:47.748766Z","shell.execute_reply":"2024-02-23T06:41:47.773419Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"highest_selling_product = df.groupby(['Year', 'Category', 'Sub-Category'])['Sales'].sum().reset_index()\n\n# Find the index of the row with the highest sales in each year\nidx = highest_selling_product.groupby('Year')['Sales'].idxmax()\n\n# Select the corresponding rows\nhighest_selling_product = highest_selling_product.loc[idx]\n\nprint('Best Performance Product Category and Sub Category for Each Year')\nprint(highest_selling_product[['Year', 'Category', 'Sub-Category', 'Sales']])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:50.823127Z","iopub.execute_input":"2024-02-23T06:41:50.824267Z","iopub.status.idle":"2024-02-23T06:41:50.845499Z","shell.execute_reply.started":"2024-02-23T06:41:50.824232Z","shell.execute_reply":"2024-02-23T06:41:50.844264Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.barplot(x='Year', y='Sales', hue='Sub-Category', data=highest_selling_product)\nplt.title('Best Performing Product Sub Category for Each Year')\nplt.xlabel('Product Sub-Category')\nplt.ylabel('Sales Revenue')\nplt.legend(loc='upper left', bbox_to_anchor=(1, 1))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:41:52.978322Z","iopub.execute_input":"2024-02-23T06:41:52.978725Z","iopub.status.idle":"2024-02-23T06:41:53.257099Z","shell.execute_reply.started":"2024-02-23T06:41:52.978697Z","shell.execute_reply":"2024-02-23T06:41:53.255815Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Forecasting Sales with ARIMA","metadata":{}},{"cell_type":"code","source":"#pip install pmdarima","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sorting date\ndf[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"], format='%d/%m/%Y')\nsorted_date = df[\"Order Date\"].sort_values()\nprint(sorted_date)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:42:13.142811Z","iopub.execute_input":"2024-02-23T06:42:13.14329Z","iopub.status.idle":"2024-02-23T06:42:13.169433Z","shell.execute_reply.started":"2024-02-23T06:42:13.143254Z","shell.execute_reply":"2024-02-23T06:42:13.168693Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pmdarima import auto_arima\nsales_by_category = df.groupby([\"Category\", df[\"Order Date\"].dt.year])[\"Sales\"].sum().reset_index()\n\n# Define a function to forecast sales for each category\ndef forecast_sales(category_data):\n    sales_series = category_data.set_index(\"Order Date\")[\"Sales\"]\n    model = auto_arima(sales_series, seasonal=True, suppress_warnings=True, stepwise=True)\n    forecast = model.predict(n_periods=1)\n    return pd.Series({\n        \"Category\": category_data[\"Category\"].iloc[0],\n        \"Forecasted_Sales_2019\": forecast.sum()\n    })\n\n# Applying the forecast_sales function to each category group\nforecasted_sales = sales_by_category.groupby(\"Category\").apply(forecast_sales).reset_index(drop=True)\n\n# Formatting the Forecasted_Sales_2019 column\nforecasted_sales[\"Forecasted_Sales_2019\"] = forecasted_sales[\"Forecasted_Sales_2019\"].apply(lambda x: '{:,.2f}'.format(x))\n\n# Displaying the result\nprint(\"Forecasted Sales in 2019 for Each Product Category:\")\nprint(forecasted_sales[[\"Category\", \"Forecasted_Sales_2019\"]])","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:42:18.021235Z","iopub.execute_input":"2024-02-23T06:42:18.021632Z","iopub.status.idle":"2024-02-23T06:42:18.830377Z","shell.execute_reply.started":"2024-02-23T06:42:18.021602Z","shell.execute_reply":"2024-02-23T06:42:18.829195Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Forecasting Sales with SARIMA","metadata":{}},{"cell_type":"code","source":"#pip install statsmodels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\n\n\nsales_by_category = df.groupby([\"Category\", df[\"Order Date\"].dt.year])[\"Sales\"].sum().reset_index()\n\n# Define a function to forecast sales for each category using SARIMAX\ndef forecast_sales(category_data):\n    sales_series = category_data.set_index(\"Order Date\")[\"Sales\"]\n    sarima_model = SARIMAX(sales_series, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n    sarima_results = sarima_model.fit()\n    forecast = sarima_results.get_forecast(steps=1).predicted_mean\n    return pd.Series({\n        \"Category\": category_data[\"Category\"].iloc[0],\n        \"Forecasted_Sales_2019\": forecast.iloc[0]\n    })\n\n# Applying the forecast_sales function to each category group\nforecasted_sales = sales_by_category.groupby(\"Category\").apply(forecast_sales).reset_index(drop=True)\n\n# Formatting the Forecasted_Sales_2019 column\nforecasted_sales[\"Forecasted_Sales_2019\"] = forecasted_sales[\"Forecasted_Sales_2019\"].apply(lambda x: '{:,.2f}'.format(x))\n\n# Displaying the result\nprint(\"Forecasted Sales in 2019 for Each Product Category:\")\nprint(forecasted_sales[[\"Category\", \"Forecasted_Sales_2019\"]])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:42:24.492651Z","iopub.execute_input":"2024-02-23T06:42:24.493088Z","iopub.status.idle":"2024-02-23T06:42:24.654838Z","shell.execute_reply.started":"2024-02-23T06:42:24.493036Z","shell.execute_reply":"2024-02-23T06:42:24.653295Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Forecasting Sales with LightGBM","metadata":{}},{"cell_type":"code","source":"#pip install lightgbm scikit-learn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\n# Assuming df is your DataFrame\nsales_by_category = df.groupby([\"Category\", df[\"Order Date\"].dt.year])[\"Sales\"].sum().reset_index()\nforecasted_sales_list = []  # List to store individual DataFrames\ntarget_year = 2020\n\n# Fitting lightgbm model\nfor category in sales_by_category[\"Category\"].unique():\n    category_data = sales_by_category[sales_by_category[\"Category\"] == category]\n    category_data[\"Order Date\"] = pd.to_datetime(category_data[\"Order Date\"])\n    category_data[\"Year\"] = category_data[\"Order Date\"].dt.year\n    train_data, valid_data = train_test_split(category_data, test_size=0.2, shuffle=False)\n    features = [\"Year\"]\n    target = \"Sales\"\n    train_dataset = lgb.Dataset(train_data[features], label=train_data[target])\n    params = {\n        \"objective\": \"regression\",\n        \"metric\": \"mse\",\n        \"boosting_type\": \"gbdt\",\n        \"num_leaves\": 31,\n        \"learning_rate\": 0.05\n    }\n    model = lgb.train(params, train_dataset, num_boost_round=1000)\n    forecast_data = pd.DataFrame({\"Year\": [target_year]})\n    forecast = model.predict(forecast_data)\n    \n    # Append individual DataFrames to the list\n    forecasted_sales_list.append(pd.DataFrame({\n        \"Category\": [category],\n        \"Forecasted_Sales_2020\": forecast.sum()\n    }))\n\n# Concatenate individual DataFrames into the final result\nforecasted_sales = pd.concat(forecasted_sales_list, ignore_index=True)\n\n# Format the Forecasted_Sales_2020 column\nforecasted_sales[\"Forecasted_Sales_2020\"] = forecasted_sales[\"Forecasted_Sales_2020\"].apply(lambda x: '{:,.2f}'.format(x))\n\nprint(\"Forecasted Sales in 2020 for Each Product Category:\")\nprint(forecasted_sales[[\"Category\", \"Forecasted_Sales_2020\"]])","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:42:30.430692Z","iopub.execute_input":"2024-02-23T06:42:30.431138Z","iopub.status.idle":"2024-02-23T06:42:30.787517Z","shell.execute_reply.started":"2024-02-23T06:42:30.431092Z","shell.execute_reply":"2024-02-23T06:42:30.786301Z"},"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Forecasting Sales with Random Forest","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\n\n# Grouping the data and resetting index\nsales_by_category = df.groupby([\"Category\", df[\"Order Date\"].dt.year])[\"Sales\"].sum().reset_index(name=\"Sales\")\n\n# Initialize the DataFrame outside the loop\nforecasted_sales = pd.DataFrame(columns=[\"Category\", \"Forecasted_Sales_2020\"])\ntarget_year = 2020\n\nfor category in sales_by_category[\"Category\"].unique():\n    # Filter data for the current category\n    category_data = sales_by_category[sales_by_category[\"Category\"] == category]\n    \n    # Ensure that 'Order Date' is interpreted as an integer (year), not a date\n    category_data = category_data.rename(columns={\"Order Date\": \"Year\"})\n    \n    # Split the data into training and validation sets\n    train_data, valid_data = train_test_split(category_data, test_size=0.2, shuffle=False)\n    \n    # Define features and target\n    features = [\"Year\"]  # 'Year' instead of 'Order Date'\n    target = \"Sales\"\n    \n    # Instantiate and train the model\n    model = RandomForestRegressor(n_estimators=100, random_state=42)\n    model.fit(train_data[features], train_data[target])\n    \n    # Create forecast data for the target year\n    forecast_data = pd.DataFrame({\n        \"Year\": [target_year]\n    })\n    \n    # Predicting the sales for the target year\n    forecast = model.predict(forecast_data)\n    \n    # Create a DataFrame for the new row\n    new_row = pd.DataFrame({\n        \"Category\": [category],\n        \"Forecasted_Sales_2020\": [forecast[0]]\n    })\n    \n    # Appending the new row to the forecasted_sales DataFrame\n    forecasted_sales = pd.concat([forecasted_sales, new_row], ignore_index=True)\n\n# Formatting the 'Forecasted_Sales_2020' column to have commas and two decimal places\nforecasted_sales[\"Forecasted_Sales_2020\"] = forecasted_sales[\"Forecasted_Sales_2020\"].apply(lambda x: '{:,.2f}'.format(x))\n\n# Printing the forecasted sales for each category for the year 2020\nprint(\"Forecasted Sales in 2020 for Each Product Category:\")\nprint(forecasted_sales)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:43:00.196599Z","iopub.execute_input":"2024-02-23T06:43:00.19698Z","iopub.status.idle":"2024-02-23T06:43:00.802352Z","shell.execute_reply.started":"2024-02-23T06:43:00.196949Z","shell.execute_reply":"2024-02-23T06:43:00.801333Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Forecasting Sales with LSTM","metadata":{}},{"cell_type":"code","source":"#pip install tensorflow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\n\n\n# Grouping the data and resetting the index\nsales_by_category = df.groupby([\"Category\", df[\"Order Date\"].dt.year])[\"Sales\"].sum().reset_index()\n\n# Initialize the DataFrame outside the loop\nforecasted_sales = pd.DataFrame(columns=[\"Category\", \"Forecasted_Sales_2020\"])\ntarget_year = 2020\n\nfor category in sales_by_category[\"Category\"].unique():\n    category_data = sales_by_category[sales_by_category[\"Category\"] == category]\n    \n    # Scale the 'Sales' data\n    scaler = MinMaxScaler()\n    category_data['Sales'] = scaler.fit_transform(category_data['Sales'].values.reshape(-1, 1))\n    \n    # Prepare the features and target for the LSTM model\n    X = category_data['Sales'].values\n    y = category_data['Sales'].values\n    X = X.reshape((X.shape[0], 1, 1))\n    \n    # Define and compile the LSTM model\n    model = Sequential()\n    model.add(LSTM(50, input_shape=(1, 1)))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    \n    # Fit the model\n    model.fit(X, y, epochs=100, batch_size=16, verbose=0)\n    \n    # Prepare the forecast data\n    forecast_data = np.array([scaler.transform([[target_year]])])\n    forecast_data = forecast_data.reshape((1, 1, 1))\n    \n    # Make the forecast\n    forecast = model.predict(forecast_data)\n    forecast = scaler.inverse_transform(forecast.reshape(-1, 1))[0][0]\n    \n    # Add the forecast to the forecasted_sales DataFrame\n    new_row = pd.DataFrame({\n        \"Category\": [category],\n        \"Forecasted_Sales_2020\": [forecast]\n    })\n    forecasted_sales = pd.concat([forecasted_sales, new_row], ignore_index=True)\n\n# Format the 'Forecasted_Sales_2020' column\nforecasted_sales[\"Forecasted_Sales_2020\"] = forecasted_sales[\"Forecasted_Sales_2020\"].apply(lambda x: '{:,.2f}'.format(x))\n\n# Print the forecasted sales\nprint(\"Forecasted Sales in 2020 for Each Product Category:\")\nprint(forecasted_sales)","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:43:07.181438Z","iopub.execute_input":"2024-02-23T06:43:07.18205Z","iopub.status.idle":"2024-02-23T06:43:19.060941Z","shell.execute_reply.started":"2024-02-23T06:43:07.182003Z","shell.execute_reply":"2024-02-23T06:43:19.059807Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\n# Grouping the data and resetting the index\nsales_by_category = df.groupby([\"Category\", df[\"Order Date\"].dt.year])[\"Sales\"].sum().reset_index()\n\n# Initialize the DataFrame outside the loop\nforecasted_sales = pd.DataFrame(columns=[\"Category\", \"Forecasted_Sales_2020\"])\ntarget_year = 2020\n\nfor category in sales_by_category[\"Category\"].unique():\n    category_data = sales_by_category[sales_by_category[\"Category\"] == category]\n    category_data = category_data.assign(Year=pd.to_datetime(category_data[\"Order Date\"]).dt.year)\n    train_data, valid_data = train_test_split(category_data, test_size=0.2, shuffle=False)\n    features = [\"Year\"]\n    target = \"Sales\"\n    \n    train_dataset = lgb.Dataset(train_data[features], label=train_data[target])\n    params = {\n        \"objective\": \"regression\",\n        \"metric\": \"mse\",\n        \"boosting_type\": \"gbdt\",\n        \"num_leaves\": 31,\n        \"learning_rate\": 0.05\n    }\n    \n    model = lgb.train(params, train_dataset, num_boost_round=1000)\n    forecast_data = pd.DataFrame({\n        \"Year\": [target_year]\n    })\n    \n    forecast = model.predict(forecast_data)\n    new_row = pd.DataFrame({\n        \"Category\": [category],\n        \"Forecasted_Sales_2020\": [forecast.sum()]\n    })\n    forecasted_sales = pd.concat([forecasted_sales, new_row], ignore_index=True)\n\nforecasted_sales[\"Forecasted_Sales_2020\"] = forecasted_sales[\"Forecasted_Sales_2020\"].apply(lambda x: '{:,.2f}'.format(x))\nprint(\"Forecasted Sales in 2020 for Each Product Category:\")\nprint(forecasted_sales)\n\nresult = []\nfor category in sales_by_category[\"Category\"].unique():\n    category_data = sales_by_category[sales_by_category[\"Category\"] == category]\n    category_data = category_data.assign(Year=pd.to_datetime(category_data[\"Order Date\"]).dt.year)\n    train_data, valid_data = train_test_split(category_data, test_size=0.2, shuffle=False)\n    features = [\"Year\"]\n    target = \"Sales\"\n    \n    train_dataset = lgb.Dataset(train_data[features], label=train_data[target])\n    model = lgb.train(params, train_dataset, num_boost_round=1000)\n    forecast_data = pd.DataFrame({\n        \"Year\": [target_year]\n    })\n    \n    forecast = model.predict(forecast_data)\n    true_values = valid_data[target]\n    predicted_values = model.predict(valid_data[features])\n    mae = mean_absolute_error(true_values, predicted_values)\n    residuals = true_values - predicted_values\n    result.append({\n        \"Category\": category,\n        \"True_Values\": true_values.values,\n        \"Predicted_Values\": predicted_values,\n        \"MAE\": mae,\n        \"Residual\": residuals.values\n    })\n\nfor i in result:\n    print(f\"Product Category: {i['Category']}\")\n    print(f\"True Values: {i['True_Values']}\")\n    print(f\"Predicted_Values: {i['Predicted_Values']}\")\n    print(f\"MAE: {i['MAE']}\")\n    print(f\"Residual: {i['Residual']}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-02-23T06:43:24.616013Z","iopub.execute_input":"2024-02-23T06:43:24.617409Z","iopub.status.idle":"2024-02-23T06:43:25.148457Z","shell.execute_reply.started":"2024-02-23T06:43:24.617372Z","shell.execute_reply":"2024-02-23T06:43:25.147143Z"},"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null}]}